#### Dataset preparation (Please note, for checking the compliance of the data, preprocessing of the data set must be done before training).

##### preprocess_config.json

- dataset_path：The path of dataset，**please make sure to include the trailing '/'**
- total_num：The total num of games, please note, it should include tendency/vote/players_[0,1,...,total_num-1]
- original_invalid：Invalid files originally present under the dataset (such as when a particular round encounters issues leading to the inability to generate tendency/vote files), organized in list format. If there are none, it should be an empty list.

Please run `python dataset/preprocess.py` first, then open 1ErrorInf.txt under the dataset path to view information about error files and make necessary modifications. Run the process again until all error files cannot be modified.

#### Model training

##### parameter explanation of config.json (config-OneRound.json&config-TwoRound.json)

- dataset_path：The path of dataset，**please make sure to include the trailing '/'**.
- heads：The number of heads in the multi-head attention mechanism.
- hidden_channels：The output dimension of the first GATv2 layer.
- hidden_channels1：The output dimension of the second GATv2 layer.
- aggr：The aggregation scheme to use for grouping node embeddings generated by different relations in HeteroConv operation.
- p：The probability of setting an element to zero during the dropout operation
- seed：the value of fixed random seed
- patience：When the model's loss on the validation set is higher in epochs [i+1, i+2, ..., i+patience] (a consecutive patience rounds) than in epoch i, it indicates that epoch i is the optimal model. Training is then stoped.
- model_save：Path to save the optimal model.
- train_size：Proportion of (training set + validation set).
- folds：Number of folds for cross-validation.
- lr：Learning rate.
- weight_decay：Used in optimization algorithms.
- train/val/test_batch_size: The batch size of training/validation/test set
- original_random_state：In our experiments, the value of `random_state` ranges from 1 to 10. This value is used to specify the initial random state. In order to avoid unexpected termination of model training due to certain unforeseen circumstances at a particular random state, training can be resumed from the failed random state.

#### Get the expert observation

You can call the `call_expert` function in GetExpert.py to obtain the name of spy in expert's observation.